{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "max_len = 40\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5       5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6       5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7       5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8       5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9       5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_excel(\"–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls\")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "\n",
    "X = df_train['Content']\n",
    "y = df_train['Rating']\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, Y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_corpus = \" \".join(X_train)\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rozhnov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " '—É–¥–æ–±–Ω–æ',\n",
       " '—Ä–∞–±–æ—Ç–∞—Ç—å',\n",
       " '—É–¥–æ–±–Ω—ã–π',\n",
       " '–æ—Ç–ª–∏—á–Ω–æ',\n",
       " '–Ω—Ä–∞–≤–∏—Ç—å—Å—è',\n",
       " '—Ö–æ—Ä–æ—à–∏–π',\n",
       " '–æ—Ç–ª–∏—á–Ω—ã–π',\n",
       " '—Ç–µ–ª–µ—Ñ–æ–Ω',\n",
       " '—Å—É–ø–µ—Ä']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16527, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_train['Content']], dtype=np.int32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(df_train['Rating'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.8157 - accuracy: 0.0488WARNING:tensorflow:From /Users/rozhnov/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "30/30 [==============================] - 4s 139ms/step - loss: 1.4100 - accuracy: 0.6670 - val_loss: 0.9538 - val_accuracy: 0.7217\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 4s 119ms/step - loss: 0.9350 - accuracy: 0.7230 - val_loss: 0.7940 - val_accuracy: 0.7695\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.7725 - accuracy: 0.7572 - val_loss: 0.6968 - val_accuracy: 0.7713\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 4s 138ms/step - loss: 0.7010 - accuracy: 0.7644 - val_loss: 0.6678 - val_accuracy: 0.7792\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.6771 - accuracy: 0.7692 - val_loss: 0.6589 - val_accuracy: 0.7792\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 4s 143ms/step - loss: 0.6657 - accuracy: 0.7705 - val_loss: 0.6550 - val_accuracy: 0.7816\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.6563 - accuracy: 0.7736 - val_loss: 0.6523 - val_accuracy: 0.7828\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 4s 118ms/step - loss: 0.6496 - accuracy: 0.7775 - val_loss: 0.6488 - val_accuracy: 0.7828\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 4s 140ms/step - loss: 0.6451 - accuracy: 0.7768 - val_loss: 0.6459 - val_accuracy: 0.7822\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.6399 - accuracy: 0.7789 - val_loss: 0.6453 - val_accuracy: 0.7834\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 4s 129ms/step - loss: 0.6332 - accuracy: 0.7810 - val_loss: 0.6442 - val_accuracy: 0.7858\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 4s 130ms/step - loss: 0.6279 - accuracy: 0.7825 - val_loss: 0.6427 - val_accuracy: 0.7840\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 114ms/step - loss: 0.6229 - accuracy: 0.7840 - val_loss: 0.6448 - val_accuracy: 0.7852\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 48ms/step - loss: 0.6299 - accuracy: 0.7828\n",
      "\n",
      "\n",
      "Test score: 0.6299067139625549\n",
      "Test accuracy: 0.7827581167221069\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = vect.fit_transform(X_train)\n",
    "valid_ft = vect.transform(df_train['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rozhnov/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(train_ft, Y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232247446633428"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgr.predict(valid_ft)\n",
    "accuracy_score(y.to_numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "modelW2V = Word2Vec(sentences=df_train['Content'].apply(str.split), size=100, window=5, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_idf = TfidfVectorizer()\n",
    "vect_idf.fit_transform(df_train['Content'])\n",
    "tfidf = dict(zip(vect_idf.get_feature_names(), vect_idf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = vect_idf.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idf = max(vect_idf.idf_)\n",
    "\n",
    "word2weight = defaultdict(\n",
    "    lambda: max_idf,\n",
    "    [(w, vect_idf.idf_[i]) for w, i in vect_idf.vocabulary_.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vect_mean(txt):\n",
    "    vector_w2v = np.zeros(100)\n",
    "    n_w2v = 0\n",
    "    for wrd in txt.split():\n",
    "        if wrd in modelW2V:\n",
    "            vector_w2v += modelW2V[wrd]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector_w2v = vector_w2v / n_w2v\n",
    "    return vector_w2v\n",
    "\n",
    "def get_vect_idf(txt):\n",
    "    vector_w2v = np.zeros(100)\n",
    "    n_w2v = 0\n",
    "    for wrd in txt.split():\n",
    "        if wrd in modelW2V:\n",
    "            iddf_ = tfidf.get(wrd, 1.)\n",
    "            vector_w2v += modelW2V[wrd]*iddf_\n",
    "            n_w2v += iddf_\n",
    "    if n_w2v > 0:\n",
    "        vector_w2v = vector_w2v / n_w2v\n",
    "    return vector_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-df1712ae5cac>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for txt in tqdm_notebook(X_train):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92178882e20444429c0561695eebaff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-e89a2fe47eca>:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if wrd in modelW2V:\n",
      "<ipython-input-36-e89a2fe47eca>:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector_w2v += modelW2V[wrd]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-df1712ae5cac>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for txt in tqdm_notebook(df_train['Content']):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131723735c5649e894e6d09261e53771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20659.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arr_vect = []\n",
    "for txt in tqdm_notebook(X_train):\n",
    "    arr_vect.append(get_vect_mean(txt))\n",
    "    \n",
    "arr_vect_valid = []\n",
    "for txt in tqdm_notebook(df_train['Content']):\n",
    "    arr_vect_valid.append(get_vect_mean(txt))\n",
    "    \n",
    "train_w2v = np.asarray(arr_vect)    \n",
    "valid_w2v = np.asarray(arr_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rozhnov/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_w2v = LogisticRegression()\n",
    "lgr_w2v.fit(train_w2v, Y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7421462800716395"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgr_w2v.predict(valid_w2v)\n",
    "accuracy_score(y.to_numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-3fd449c2466d>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for txt in tqdm_notebook(X_train):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e761f7f7fa64c6880870b4ea2344090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-e89a2fe47eca>:16: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if wrd in modelW2V:\n",
      "<ipython-input-36-e89a2fe47eca>:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector_w2v += modelW2V[wrd]*iddf_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-3fd449c2466d>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for txt in tqdm_notebook(df_train['Content']):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065f20e4aab4478da77a364b0669c431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20659.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arr_vect = []\n",
    "for txt in tqdm_notebook(X_train):\n",
    "    arr_vect.append(get_vect_idf(txt))\n",
    "    \n",
    "arr_vect_valid = []\n",
    "for txt in tqdm_notebook(df_train['Content']):\n",
    "    arr_vect_valid.append(get_vect_idf(txt))\n",
    "    \n",
    "train_w2v = np.asarray(arr_vect)    \n",
    "valid_w2v = np.asarray(arr_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rozhnov/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lgr_w2v = LogisticRegression()\n",
    "lgr_w2v.fit(train_w2v, Y_train.to_numpy())\n",
    "y_pred = lgr_w2v.predict(valid_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7421462800716395"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y.to_numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ù–µ–π—Ä–æ—Å–µ—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 0\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size=20, embedding_dim = 128, out_channel = 128, num_classes = num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(out_channel, num_classes)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        output = self.embedding(x)\n",
    "        #                       B  F  L         \n",
    "        output = output.permute(0, 2, 1)\n",
    "        output = self.conv(output)\n",
    "        output = self.relu(output)\n",
    "        output = torch.max(output, axis=2).values\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, target=None, transform=None):\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        if target is not None:\n",
    "            self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index] if self.target is not None else None\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(200, 128)\n",
      "  (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (relu): ReLU()\n",
      "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
      ")\n",
      "Parameters: 75654\n",
      "Train epoch 1/20\n",
      "Step 0: loss=1.6116347312927246\n",
      "Train epoch 2/20\n",
      "Step 0: loss=0.7282378077507019\n",
      "Train epoch 3/20\n",
      "Step 0: loss=0.5747666954994202\n",
      "Train epoch 4/20\n",
      "Step 0: loss=0.5657120943069458\n",
      "Train epoch 5/20\n",
      "Step 0: loss=0.4742121994495392\n",
      "Train epoch 6/20\n",
      "Step 0: loss=0.5286418795585632\n",
      "Train epoch 7/20\n",
      "Step 0: loss=0.41174596548080444\n",
      "Train epoch 8/20\n",
      "Step 0: loss=0.33086180686950684\n",
      "Train epoch 9/20\n",
      "Step 0: loss=0.3667222857475281\n",
      "Train epoch 10/20\n",
      "Step 0: loss=0.36188963055610657\n",
      "Train epoch 11/20\n",
      "Step 0: loss=0.3218509256839752\n",
      "Train epoch 12/20\n",
      "Step 0: loss=0.3637925386428833\n",
      "Train epoch 13/20\n",
      "Step 0: loss=0.29337257146835327\n",
      "Train epoch 14/20\n",
      "Step 0: loss=0.3148404061794281\n",
      "Train epoch 15/20\n",
      "Step 0: loss=0.33569779992103577\n",
      "Train epoch 16/20\n",
      "Step 0: loss=0.3980589210987091\n",
      "Train epoch 17/20\n",
      "Step 0: loss=0.38856276869773865\n",
      "Train epoch 18/20\n",
      "Step 0: loss=0.30643346905708313\n",
      "Train epoch 19/20\n",
      "Step 0: loss=0.33990582823753357\n",
      "Train epoch 20/20\n",
      "Step 0: loss=0.30391886830329895\n"
     ]
    }
   ],
   "source": [
    "model = Net(vocab_size=max_words)\n",
    "\n",
    "print(model)\n",
    "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "model.train()\n",
    "#model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=10e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "train_dataset = DataWrapper(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DataWrapper(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"Train epoch {epoch}/{epochs}\")\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # data = data.cuda()\n",
    "        # target = target.cuda()\n",
    "        \n",
    "        # compute output\n",
    "        output = model(data)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        target = torch.argmax(target, dim=1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%print_batch_n == 0:\n",
    "            loss = loss.float().item()\n",
    "            print(\"Step {}: loss={}\".format(i, loss))\n",
    "            loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Loss history')\n",
    "plt.grid(True)\n",
    "plt.ylabel('Train loss')\n",
    "plt.xlabel('Step')\n",
    "plt.plot(loss_history);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
